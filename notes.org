# Went over syllabus and summary of topics
* Parallel computing
** Why parallel computing?
<2021-01-13 Wed>
- A problem is broken down into discrete parts that can be solved concurrently.
- Each part is further broken down. Example: map reduce
- In nature, many complex events happen at the same time, but within a temporal sequence
- Big data
  # we then spent like the next 40 minutes talking about lab schedules lol
  # Lab 1 will be released tomorrow: <2021-01-14 Thu>
  # All the labs happen on the same week, you can attend either Tuesday or Thursday at 2pm

** Parallel hardware: SIMD, MIMD, shared-memory systems, distributed memory systems

** Parallel software; threads & shared memory, processes and message passing, distributed shared memory, distributed shared data

** Performance: speedup & Amdahl's law


* Shared Memory Programming with Pthreads
** Processes, threads, pthreads
** Critical sections

* OpenMP (Shared Memory Programming)
* MPI (Distributed Memory Programming)
Message
Passing 
Interface

* Parallel Algorithms Design
* Big Data Processing and Spark
