{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flynn taxonomy\n",
    "\n",
    "- SISD\n",
    "SISD stands for Single Instruction Stream, Single Data Stream. A SISD system has a single uniprocessor, which executes a single instruction stream to operate on data stored in a single memory.\n",
    "Example: uniprocessor, first superscalar processors\n",
    "\n",
    "- SIMD\n",
    "SIMD stands for Single Instruction Stream, Multiple Data Stream. A SIMD system has multiple processing units which all simultaneously do the same operation on multiple points in a data pool in a synchronized fashion. \n",
    "Example: GPU\n",
    "\n",
    "- MISD\n",
    "MISD stands for Multiple Instruction Stream, Single Data Stream. A MISD system has multiple processing units performing different operations on thesame data simultaneously. It can be used for reliability or fault tolerance, if thesame operation is being done multiple times on the same data\n",
    "Example: fault tolerance, space shuttle flight control\n",
    "\n",
    "- MIMD\n",
    "MIMD stands for Multiple Instruction Stream, Multiple Data Stream. A MIMD system has many processing units which each perform operations independently from each other at the same time. That is, each unit can be doing differentoperations on different pieces of data at any given time.\n",
    "Example: modern multicore CPU\n",
    "\n",
    "## Relation betweet SIMD MIMD SPMD\n",
    "for all of them, the processor has access to multiple data streams\n",
    "they are not the same\n",
    "SIMD only deals with a single instruction stream, while MIMD and SPMD both use multiple instruction streams\n",
    "\n",
    "SPMD is a subcategory of MIMD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared Memory vs Distributed Memory\n",
    "\n",
    "## Shared Memory\n",
    "\n",
    "### Pros\n",
    "+ user friendly programming perspective to memory\n",
    "+ data sharing between tasks is fast and uniform\n",
    "\n",
    "### Cons\n",
    "- no scalability between memory and CPUs\n",
    "- if you want more power,\n",
    "\n",
    "## Distributed Memory\n",
    "\n",
    "### Pros\n",
    "+ memory is scalable with the number of processors\n",
    "+ this is cost effective, because lots of cheap, commodity hardware can be used as opposed to upgrading a monolithic, more expensive structure\n",
    "\n",
    "### Cons\n",
    "- data communication between processors is more difficult\n",
    "- it is difficult to map existing data structures to the memory organization\n",
    "- memory access times can be very different. For example, local access times vs over a network\n",
    "  access times can be much slower compared to a MIMD system\n",
    "- more overhead for the programmer. The programmer has to think about message passing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amdahl's law\n",
    "If y fraction of a serial program cannot be parallelized, 1/y is an upper bound on the speedup of its parallel program\n",
    "\n",
    "S(p) = T1/Tp <= 1/( x/p + 1 - x)\n",
    "\n",
    "lim_p->inf <= 1/(1-x)\n",
    "\n",
    "Tp = T1/p + T_overhead\n",
    "\n",
    "Efficiency\n",
    "E(p) = S(p)/p = T1 / (p * Tp)\n",
    "\n",
    "linear/ideal speedup\n",
    "S(p) = p\n",
    "\n",
    "sublinear speedup (common)\n",
    "S(p) < p\n",
    "\n",
    "slowdown\n",
    "S(p+1) < S(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let T_serial = N\n",
    "\n",
    "T_overhead = sqrt(P)\n",
    "\n",
    "find P such that there is 12% degradation compared to ideal speedup\n",
    "\n",
    "-> so that means the efficiency is 0.88\n",
    "\n",
    "0.88 = N/ (p * ((N/p) + sqrt(p)))\n",
    "wolfram:\n",
    "p =  (3/22)^(2/3) * N^(2/3)\n",
    "\n",
    " = 128 (3/11)^(2/3) 2^(1/3)\n",
    " = 67.82227413238058016390\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multithreaded program examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// min max\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <pthread.h>\n",
    "\n",
    "#define NUM_ELEMENTS 1000000\n",
    "\n",
    "int thread_count;\n",
    "int* data; // array of integer values\n",
    "\n",
    "void* min_max_task(void* thread_id);\n",
    "int min_value;\n",
    "int max_value;\n",
    "\n",
    "int* generate_values(int n){\n",
    "    int* vec = malloc(n * sizeof int));\n",
    "    for (int i=0; i<n; ++i){\n",
    "        vec[i] = rand()  % NUM_ELEMENTS;\n",
    "    }\n",
    "    return vec;\n",
    "}\n",
    "\n",
    "int main(int argc, char* argv[]){\n",
    "    pthread_t* thread_handles;\n",
    "    thread_count = 1\n",
    "    if (argc > 1){\n",
    "        thread_count = strtol(argv[i], NULL, 10);\n",
    "    }\n",
    "    thread_handles = malloc(thread_count * sizeof(pthread_t));\n",
    "    data = generate_values(NUM_ELEMENTS);\n",
    "    // insert here\n",
    "    pthread_mutex_init(&mutex, NULL);multithrea\n",
    "\n",
    "    for (long thread=0; thread< thread_count; thread++){\n",
    "        pthread_create(&thread_handles[thread], NULL, min_max_task, (void*) thread);\n",
    "    }\n",
    "\n",
    "    for(long thread=0; thread< thread_countl thread++){\n",
    "        pthread_join(thread_handles[thread], NULL);\n",
    "    }\n",
    "    printf(\"Minumum value is %d\\n\", min_value);\n",
    "    printf(\"Maximum value is %d\\n\", max_value)\n",
    "}\n",
    "\n",
    "// insert here\n",
    "pthread_mutex_t mutex;\n",
    "\n",
    "// remember to insert this in main function\n",
    "// pthread_mutex_init(&mutex, NULL);\n",
    "\n",
    "void* min_max_task(void* thread_id){\n",
    "    int id = (int) thread_id;\n",
    "    int start = id * NUM_ELEMENTS/thread_count;\n",
    "    int end = (id+1) * NUM_ELEMENTS/thread_count -1;\n",
    "\n",
    "    for (int i=start; i<=end; i++){\n",
    "        pthread_mutex_lock(&mutex);\n",
    "        if (data[i] < min_value){\n",
    "            min_value = data[i];\n",
    "        }\n",
    "        if (max_value < data[i]){\n",
    "            max_value = data[i];\n",
    "        }\n",
    "        pthread_mutex_unlock(&mutex);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multiple executions of the program produce different results\n",
    "\n",
    "can happen because of lack of synchronization mechanisms which don't ensure the integrity of the data being modified\n",
    "\n",
    "need to use mutex locks/condition variables when  doing computation on arrays simultaneously\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pthread_mutex_t mutex;\n",
    "pthread_cond_t condvar;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// with rwlock\n",
    "/*\n",
    "Created by Di Niu on Jan 26, 2016\n",
    "Demonstrate the use of Read-Write locks in a \n",
    "program to find the minimum value in a list.\n",
    "*/\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "#include <unistd.h>\n",
    "#include <pthread.h>\n",
    "#include \"timer.h\"\n",
    "\n",
    "typedef struct {\n",
    "\tint readers;\n",
    "\tint writer;\n",
    "\tpthread_cond_t readers_proceed;\n",
    "\tpthread_cond_t writer_proceed;\n",
    "\tint pending_writers;\n",
    "\tpthread_mutex_t read_write_lock;\n",
    "} mylib_rwlock_t;\n",
    "\n",
    "const int MAX_INT  = 10000000;\n",
    "int partial_list_size;\n",
    "int min_value;\n",
    "\n",
    "pthread_mutex_t mutex;\n",
    "mylib_rwlock_t rwlock; \n",
    "\n",
    "\n",
    "void mylib_rwlock_init (mylib_rwlock_t *l) {\n",
    "\tl -> readers = l -> writer = l -> pending_writers = 0;\n",
    "\tpthread_mutex_init(&(l -> read_write_lock), NULL);\n",
    "\tpthread_cond_init(&(l -> readers_proceed), NULL);\n",
    "\tpthread_cond_init(&(l -> writer_proceed), NULL);\n",
    "}\n",
    "\n",
    "\n",
    "void mylib_rwlock_rlock(mylib_rwlock_t *l) {\n",
    "\t/* if there is a write lock or pending writers, perform condition wait, else increment count of readers and grant read lock */\n",
    "\n",
    "\tpthread_mutex_lock(&(l -> read_write_lock));\n",
    "\twhile ((l -> pending_writers > 0) || (l -> writer > 0))\n",
    "\t\tpthread_cond_wait(&(l -> readers_proceed),\n",
    "\t\t\t&(l -> read_write_lock));\n",
    "\tl -> readers ++;\n",
    "\tpthread_mutex_unlock(&(l -> read_write_lock));\n",
    "}\n",
    "\n",
    "void mylib_rwlock_wlock(mylib_rwlock_t *l) {\n",
    "\t/* if there are readers or writers, increment pending writers count and wait. On being woken, decrement pending writers count and increment writer count */\n",
    "\t\n",
    "\tpthread_mutex_lock(&(l -> read_write_lock));\n",
    "\twhile ((l -> writer > 0) || (l -> readers > 0)) {\n",
    "\t\tl -> pending_writers ++;\n",
    "\t\tpthread_cond_wait(&(l -> writer_proceed),\n",
    "\t\t\t&(l -> read_write_lock));\n",
    "    \tl -> pending_writers --;\n",
    "\t}\n",
    "\tl -> writer ++;\n",
    "\tpthread_mutex_unlock(&(l -> read_write_lock));\n",
    "}\n",
    "\n",
    "void mylib_rwlock_unlock(mylib_rwlock_t *l) {\n",
    "\t/* if there is a write lock then unlock, else if there are read locks, decrement count of read locks. If the count is 0 and there is a pending writer, let it through, else if there are pending readers, let them all go through */\n",
    "\n",
    "\tpthread_mutex_lock(&(l -> read_write_lock));\n",
    "\tif (l -> writer > 0)\n",
    "\t\tl -> writer = 0;\n",
    "\telse if (l -> readers > 0)\n",
    "\t\tl -> readers --;\n",
    "\tpthread_mutex_unlock(&(l -> read_write_lock));\n",
    "\tif ((l -> readers == 0) && (l -> pending_writers > 0))\n",
    "\t\tpthread_cond_signal(&(l -> writer_proceed));\n",
    "\telse if (l -> readers > 0)\n",
    "\t\tpthread_cond_broadcast(&(l -> readers_proceed));\n",
    "}\n",
    "\n",
    "void *find_min_rw(void *list_ptr) {\n",
    "\tint *partial_list_pointer, my_min, i;\n",
    "\tmy_min = MAX_INT;\n",
    "\tpartial_list_pointer = (int *) list_ptr;\n",
    "\tfor (i = 0; i < partial_list_size; i++)\n",
    "\t\tif (partial_list_pointer[i] <= my_min)\n",
    "\t\t\tmy_min = partial_list_pointer[i];\n",
    "\t// lock the mutex associated with min_value and update the variable as required \n",
    "\tmylib_rwlock_rlock(&rwlock);\n",
    "\t\n",
    "\tif (my_min < min_value) {\n",
    "\t\tmylib_rwlock_unlock(&rwlock);\n",
    "\t\tmylib_rwlock_wlock(&rwlock);\n",
    "\t\tmin_value = my_min;\n",
    "\t}\n",
    "\t\n",
    "\t// and unlock the mutex\n",
    "\tmylib_rwlock_unlock(&rwlock);\n",
    "\tpthread_exit(0);\n",
    "}\n",
    "\n",
    "\n",
    "int main(int argc, char* argv[]) {\n",
    "   int       thread, i;  \n",
    "   pthread_t* thread_handles;\n",
    "   double start, finish, elapsed;\n",
    "   long thread_count = strtol(argv[1], NULL, 10);\n",
    "   printf(\"%ld threads\\n\", thread_count);\n",
    "\n",
    "\tint n = 1000000; // problem size\n",
    "   \tint *list = (int *)malloc(n*sizeof(int));//input array\n",
    "\tfor (i = 0; i < n; i++)\n",
    "\t\tlist[i] = 99;\n",
    "\tpartial_list_size = n/thread_count;\t//problem size for each thread\n",
    "\tmin_value = MAX_INT;\n",
    "\t\n",
    "   thread_handles = (pthread_t*) malloc (thread_count*sizeof(pthread_t)); \n",
    "   pthread_mutex_init(&mutex, NULL);\n",
    "   mylib_rwlock_init(&rwlock);\n",
    "   \n",
    "   GET_TIME(start);\n",
    "   for (thread = 0; thread < thread_count; thread++)  \n",
    "      pthread_create(&thread_handles[thread], NULL,\n",
    "          find_min_rw, (void*)&list[thread*partial_list_size]);  \n",
    "\n",
    "   for (thread = 0; thread < thread_count; thread++) \n",
    "      pthread_join(thread_handles[thread], NULL); \n",
    "   GET_TIME(finish);\n",
    "   elapsed = finish - start;\n",
    "   printf(\"Time taken: %f seconds\\n\", elapsed);\n",
    "   printf(\"Min value is: %d\\n\", min_value);\n",
    "\n",
    "   pthread_mutex_destroy(&mutex);\n",
    "   free(thread_handles);\n",
    "   return 0;\n",
    "}  /* main */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// this is a barrier\n",
    "#include <pthread.h>\n",
    "typedef struct {\n",
    "  pthread_mutex_t count_lock;\n",
    "  pthread_cond_t ok_to_proceed;\n",
    "  int count;\n",
    "} mylib_barrier_t;\n",
    "\n",
    "void mylib_init_barrier(mylib_barrier_t *b) {\n",
    "  b->count = 0;\n",
    "  pthread_mutex_init(&(b->count_lock), NULL);\n",
    "  pthread_cond_init(&(b->ok_to_proceed), NULL);\n",
    "}\n",
    "\n",
    "void mylib_barrier(mylib_barrier_t *b, int num_threads) {\n",
    "  pthread_mutex_lock(&(b->count_lock));\n",
    "  b->count++;\n",
    "  if (b->count == num_threads) {\n",
    "    b->count = 0;\n",
    "    pthread_cond_broadcast(&(b->ok_to_proceed));\n",
    "  } else\n",
    "    while (pthread_cond_wait(&(b->ok_to_proceed), &(b->count_lock)) != 0)\n",
    "      ;\n",
    "  pthread_mutex_unlock(&(b->count_lock));\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//producer/consumer with barrier\n",
    "#include <pthread.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "#define BSIZE 3\n",
    "#define NUMITEMS 6\n",
    "\n",
    "typedef struct {\n",
    "  char buf[BSIZE];\n",
    "  int occupied;\n",
    "  int nextin, nextout;\n",
    "  pthread_mutex_t mutex;\n",
    "  pthread_cond_t more;\n",
    "  pthread_cond_t less;\n",
    "} buffer_t;\n",
    "buffer_t buffer;\n",
    "\n",
    "void *producer(void *);\n",
    "void *consumer(void *);\n",
    "\n",
    "#define NUM_THREADS 2\n",
    "pthread_t tid[NUM_THREADS]; /* array of thread IDs */\n",
    "\n",
    "int main(int argc, char *argv[]) {\n",
    "\n",
    "  int i;\n",
    "\n",
    "  pthread_cond_init(&(buffer.more), NULL);\n",
    "  pthread_cond_init(&(buffer.less), NULL);\n",
    "  pthread_mutex_init(&buffer.mutex, NULL);\n",
    "  pthread_create(&tid[1], NULL, consumer, NULL);\n",
    "  pthread_create(&tid[0], NULL, producer, NULL);\n",
    "  for (i = 0; i < NUM_THREADS; i++)\n",
    "    pthread_join(tid[i], NULL);\n",
    "\n",
    "  printf(\"\\nmain() reporting that all %d threads have terminated\\n\", i);\n",
    "} /* main */\n",
    "\n",
    "void *producer(void *parm) {\n",
    "\n",
    "  char item[NUMITEMS] = \"HELLO.\";\n",
    "  int i;\n",
    "\n",
    "  printf(\"producer started.\\n\");\n",
    "\n",
    "  for (i = 0; i < NUMITEMS; i++) {\n",
    "    /* produce an item, one character from item[] */\n",
    "    if (item[i] == '\\0')\n",
    "      break; /* Quit if at end of string. */\n",
    "\n",
    "    pthread_mutex_lock(&(buffer.mutex));\n",
    "\n",
    "    if (buffer.occupied >= BSIZE)\n",
    "      printf(\"producer waiting.\\n\");\n",
    "    while (buffer.occupied >= BSIZE)\n",
    "      pthread_cond_wait(&(buffer.less), &(buffer.mutex));\n",
    "    printf(\"producer executing.\\n\");\n",
    "\n",
    "    buffer.buf[buffer.nextin] = item[i];\n",
    "    buffer.nextin++;\n",
    "    buffer.nextin %= BSIZE;\n",
    "    buffer.occupied++;\n",
    "    /* now: either buffer.occupied < BSIZE and buffer.nextin\n",
    "       is the index of the next empty slot in the\n",
    "       buffer, or buffer.occupied == BSIZE and\n",
    "       buffer.nextin is the index of the next\n",
    "       (occupied) slot that will be emptied by a consumer\n",
    "\n",
    "       (such as buffer.nextin == buffer.nextout) */\n",
    "    pthread_cond_signal(&(buffer.more));\n",
    "    pthread_mutex_unlock(&(buffer.mutex));\n",
    "  }\n",
    "  printf(\"producer exiting.\\n\");\n",
    "  pthread_exit(0);\n",
    "}\n",
    "\n",
    "void *consumer(void *parm) {\n",
    "  char item;\n",
    "  int i;\n",
    "  printf(\"consumer started.\\n\");\n",
    "  for (i = 0; i < NUMITEMS; i++) {\n",
    "    /*Insert here*/\n",
    "\n",
    "    pthread_mutex_lock(&buffer.mutex);\n",
    "    if (buffer.occupied < 1)\n",
    "      printf(\"consumer waiting.\\n\");\n",
    "    while (buffer.occupied < 1)\n",
    "      pthread_cond_wait(&buffer.more, &buffer.mutex);\n",
    "    printf(\"consumer executing.\\n\");\n",
    "\n",
    "    item = buffer.buf[buffer.nextout];\n",
    "    printf(\"%c\\n\", item);\n",
    "    buffer.nextout++;\n",
    "    buffer.nextout %= BSIZE;\n",
    "    buffer.occupied--;\n",
    "\n",
    "    pthread_cond_signal(&buffer.less);\n",
    "    pthread_mutex_unlock(&buffer.mutex);\n",
    "  }\n",
    "  printf(\"consumer exiting.\\n\");\n",
    "  pthread_exit(0);\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}